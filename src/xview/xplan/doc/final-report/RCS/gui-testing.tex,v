head	1.7;
access;
symbols;
locks; strict;
comment	@% @;


1.7
date	92.12.14.09.45.05;	author lacey;	state Exp;
branches;
next	1.6;

1.6
date	92.12.14.09.16.51;	author lacey;	state Exp;
branches;
next	1.5;

1.5
date	92.12.14.07.44.48;	author lacey;	state Exp;
branches;
next	1.4;

1.4
date	92.12.14.06.16.38;	author lacey;	state Exp;
branches;
next	1.3;

1.3
date	92.12.14.04.27.37;	author lacey;	state Exp;
branches;
next	1.2;

1.2
date	92.12.14.03.51.08;	author lacey;	state Exp;
branches;
next	1.1;

1.1
date	92.12.14.00.03.09;	author lacey;	state Exp;
branches;
next	;


desc
@@


1.7
log
@*** empty log message ***
@
text
@\subsection{Testing Procedure for GUI Module}
%
% If your testing specifications were correct, then you can
% include the text for the test data description and expected 	
% results. Otherwise, incorporate the corrected descriptions.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% The following subsubsection should be repeated for each module that
% is invoked by the top-level module.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Unit tests for store-data-from-taskinfoPopup} 

\begin{description}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% What data did you use to conduct the tests?
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item[Test case data:]\hfill\\ As with most of the graphical user interface,
no specific single test elements can be given (i.e., it is impossible
to enumerate all test cases).  Some things that were be tested (and
this is true for all part of the GUI that involve keyboard input)
included:
\begin{enumerate}
\item Verifying that the user can not enter too many characters and
overflow the buffer.
\item Verifying that if the user enters nothing at all for a field,
the user is either flagged for some input, or if empty input is
acceptable, the data gets stored in a fashion that indicates that it
was not entered by the user (for instance some special value for
integers, or empty strings for character data).
\item Verifying that only specified ranges of values can be entered
(e.g., a date of 14/75/92 would be flagged as incorrect).
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Briefly, what type of results do you expect?
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item[Expected results:]\hfill\\
It was expected that the data entered into the task information screen
is the same as the data that is extracted from that same screen for storage.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% DO NOT FILL OUT THE FOLLOWING SECTION FOR THE TESTING SPEC DELIVERABLE!!
% The testing results will be turned when the practice demo is given.
%
% For each top level module, describe the testing results.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\item[Actual Test Results]\hfill\\

After extensive testing it was found that the data entered into the
GUI was indeed stored correctly into the database system

\end{description}
%----------------------------------------

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% The following subsubsection should be repeated for each module that
% is invoked by the top-level module.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Unit tests for load-data-to-taskinfoPopup} 

\begin{description}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% What data did you use to conduct the tests?
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item[Test case data:]\hfill\\ As with other modules of the GUI, several test
cases based on perceived problem areas (empty lists, etc.) along with
areas that we don't see there being a problem with.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Briefly, what type of results do you expect?
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item[Expected results:]\hfill\\ The data previously stored into the
task structure should be displayed in the task window correctly.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% DO NOT FILL OUT THE FOLLOWING SECTION FOR THE TESTING SPEC DELIVERABLE!!
% The testing results will be turned when the practice demo is given.
%
% For each top level module, describe the testing results.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\item[Actual Test Results]\hfill\\

The data that had been stored into the database was indeed displayed
again in the task information window when these tests were performed.

\end{description}

%----------------------------------------

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% The following subsubsection should be repeated for each module that
% is invoked by the top-level module.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Unit tests for fill-filelist}

\begin{description}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% What data did you use to conduct the tests?
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item[Test case data:]\hfill\\ Various directories were entered while using
the routine.  Some of them were set up to contain no files, and
others had several dozen files in them.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Briefly, what type of results do you expect?
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item[Expected results:]\hfill\\ It was expected that the file chosen from the
list is the one that is passed back to the calling routine.  In the
case of selecting a directory the correct response would be to enter
the directory selected.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% DO NOT FILL OUT THE FOLLOWING SECTION FOR THE TESTING SPEC DELIVERABLE!!
% The testing results will be turned when the practice demo is given.
%
% For each top level module, describe the testing results.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\item[Actual Test Results]\hfill\\

There seems to be a problem in this routine in that occasionally when
a directory is selected, rather than just entering that directory the
routine continues to go up (or down) the directory structure a few
more directories.

\end{description}

%----------------------------------------

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% The following subsubsection should be repeated for each module that
% is invoked by the top-level module.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Unit tests for pert-popup} 

\begin{description}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% What data did you use to conduct the tests?
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item[Test case data:]\hfill\\ The test case data for this routine 
included the entire task list which we used in MS-Project to generate
our PERT and Gantt charts for the project plan.  The output of
MS-Project was compared to the output of our project.  In addition
several test cases were generated by hand to test out areas that we
thought could cause problems, such as dependency lines that cross several
pages.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Briefly, what type of results do you expect?
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item[Expected results:]\hfill\\ The results should be similar to that
generated by MS-Project, and for smaller tests should be similar to
those charts generated by hand.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% DO NOT FILL OUT THE FOLLOWING SECTION FOR THE TESTING SPEC DELIVERABLE!!
% The testing results will be turned when the practice demo is given.
%
% For each top level module, describe the testing results.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\item[Actual Test Results]\hfill\\ The routine was tested on a number
of different task databases, and performed well with all of them.  

\end{description}

%----------------------------------------

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% The following subsubsection should be repeated for each module that
% is invoked by the top-level module.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Unit tests for gantt-popup} 

\begin{description}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% What data did you use to conduct the tests?
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item[Test case data:]\hfill\\ The data used for this test was the same as
that used in testing the pert-popup routine.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Briefly, what type of results do you expect?
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item[Expected results:]\hfill\\ The results should be very similar to that
generated by MS-Project.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% DO NOT FILL OUT THE FOLLOWING SECTION FOR THE TESTING SPEC DELIVERABLE!!
% The testing results will be turned when the practice demo is given.
%
% For each top level module, describe the testing results.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\item[Actual Test Results]\hfill\\ The routine was tested with a
number of different task files, and performed well.  The Gantt charts
looked very similar to those produced by MS-Project.

\end{description}

@


1.6
log
@*** empty log message ***
@
text
@d124 1
a124 1
There seems to be a problem in this routine in that occassionally when
@


1.5
log
@*** empty log message ***
@
text
@d1 1
a1 1
\subsection{GUI Module}
@


1.4
log
@*** empty log message ***
@
text
@d20 1
a20 1
to enumerate all test cases).  Some things that will be tested (and
d22 1
a22 1
include:
d39 1
a39 1
It is expected that the data entered into the task information screen
d104 3
a106 3
\item[Test case data:]\hfill\\ Various directories will be entered while using
the routine.  Some of them will be set up to contain no files, and
others will have several dozen files in them.
d111 1
a111 1
\item[Expected results:]\hfill\\ It is expected that the file chosen from the
d144 2
a145 2
\item[Test case data:]\hfill\\ The test case data for this routine will
include the entire task list which we used in MS-Project to generate
d147 3
a149 3
MS-Project will be compared to the output of our project.  In addition
several test cases will be generated by hand to test out areas that we
think my cause problems, such as dependency lines that cross several
d183 1
a183 1
\item[Test case data:]\hfill\\ The data used for this test will be the same as
@


1.3
log
@*** empty log message ***
@
text
@a15 22
% Describe the test for the module.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item[Description of tests:]\hfill\\
 For this module the testing centers
around making sure that the information extracted from the task window
is the same as the information that was actually entered into the
window.  The procedure will be to print out (to the screen) the
information received, and try several test cases, each time making
sure that what gets printed out is the same as what was entered.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Use of stubs or other software to facilitate the test
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item[Overhead software description:]\hfill\\ The database routines, or stubs
that match the database routine calling parameters will have to be
complete before this module is tested.  Also, for this routine and all
others that follow, the GUI code to set up the callbacks will have to
have been generated by {\tt gxv}.  Our current plan is to have
database routines completed and tested before the integration with the
GUI occurs.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
a65 20
% Describe the test for the module.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item[Description of tests:]\hfill\\ This routine takes a task as a parameter,
and fills the elements of the task information window with the
information from the task.  The test for this routine will involve
taking a task structure and filling it with data, and then calling the
routine to make sure it fills the task information window correctly.
The actual database routines will then be used to search for tasks and
display them in the task window.  Such tasks were previously stored
with store-data.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Use of stubs or other software to facilitate the test
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item[Overhead software description:]\hfill\\ The actual database routines
will be used in testing this routine, but prior to using those at
least a couple of tests will be done where the task structure is
filled ``by hand'' in a short routine that is hard-coded, and temporary.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
a101 20
% Describe the test for the module.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item[Description of tests:]\hfill\\ This routine will be tested to make sure
it lists all available files and directories in the file list.  It
will also be tested to make sure the filename that was selected from
the file list is actually the filename that gets returned to the
caller.  Finally tests will be made to make sure that the routine
correctly handles clicking on a directory (which means that the
directory should be entered).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Use of stubs or other software to facilitate the test
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item[Overhead software description:]\hfill\\ A routine that calls this
routine will have to be provided.  Since this routine will be a
callback it is most likely the case that it will be tested after the
files are generated by Guide.  In that case, the routine that calls
this routine will print out the filename returned.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
a141 15
% Describe the test for the module.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item[Description of tests:]\hfill\\ This routine will be tested to make sure
it is correctly retrieving the formatting information from the
calculation subsystem, and correctly sending the information to the
routines that do the actual display of the PERT chart to a canvas.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Use of stubs or other software to facilitate the test
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item[Overhead software description:]\hfill\\ The calculation module that
determines the positioning of items in the PERT chart will have to be
complete, along with the routines that draw single PERT boxes.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
a178 14

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Describe the test for the module.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item[Description of tests:]\hfill\\ This routine will be tested to verify it
correctly retrieves the Gantt chart formatting information from the
calculation module, and that it passes this information on correctly
to the routines which actually draw the Gantt charts.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Use of stubs or other software to facilitate the test
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item[Overhead software description:]\hfill\\ The routines mentioned in the
description of tests will have to be complete before this can be tested.
@


1.2
log
@*** empty log message ***
@
text
@d71 1
a71 1
\subsubsection{Actual Test Results}
d126 1
a126 1
\subsubsection{Actual Test Results}
d184 1
a184 1
\subsubsection{Actual Test Results}
d242 2
a243 1
\subsubsection{Actual Test Results}
a244 4

The routine was tested on a number of different task databases, and
performed well with all of them.  

d289 3
a291 5
\subsubsection{Actual Test Results}

The routine was tested with a number of different task files, and
performed well.  The Gantt charts looked very similar to those
produced by MS-Project.
@


1.1
log
@Initial revision
@
text
@d7 6
d14 62
a75 3
\item[{Test Data: }]
\item[{Expected Results: }] 
\item[{Actual Results: }]   
d77 223
@
