head	1.6;
access;
symbols;
locks; strict;
comment	@% @;


1.6
date	92.11.11.10.50.59;	author lacey;	state Exp;
branches;
next	1.5;

1.5
date	92.11.11.10.45.11;	author lacey;	state Exp;
branches;
next	1.4;

1.4
date	92.11.11.10.16.31;	author lacey;	state Exp;
branches;
next	1.3;

1.3
date	92.11.11.08.33.16;	author lacey;	state Exp;
branches;
next	1.2;

1.2
date	92.11.11.08.32.35;	author lacey;	state Exp;
branches;
next	1.1;

1.1
date	92.11.11.08.23.05;	author lacey;	state Exp;
branches;
next	;


desc
@@


1.6
log
@*** empty log message ***
@
text
@%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% From the information described in the Test plan, give the 
% actual procedure for carrying out the plans.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Test Procedure for the Graphical User Interface}

The graphical user interface is the means by which the user makes use
of the features of the software.  The graphical user interface itself
has very little functionality other than calling other routines in
the software.  In other words, most of the testing that will be done
on the GUI will be integration testing, rather than unit testing.  The
integration will be of the GUI and the specific functionality being
attached to it.

The functionality that {\em is}\/ present in the user interface
includes the ability to enter and store task information and recall
such information.  Other functionality includes displaying PERT and
Gantt charts that have been generated by the calculation routines.
Most of the testing for the GUI will center around making sure that
information that is entered is stored correctly into the database
(which of course means that we must be certain the database routines
work before testing the portions of the GUI that relate to entering
and storing data), that information is recalled correctly, and that
generated charts work without error.  Of course each connection that
is supposed to be present between a GUI component (like a button) and
function of the software will also be tested.  For instance if pushing
a button is supposed to cause a certain action to be taken, we will
test to make sure that the expected action occurs.

It is assumed that the XView libraries have been thoroughly tested,
so we will not specifically be targeting possible XView bugs in our
testing.

The remaining testing that will be done will be on odd and non-obvious
cases that could come up in using the interface.  For instance, if
someone tries to display and then edit several different tasks
simultaneously the software should be able to keep the task
information for each task being edited separate from each other, and
the information should be stored correctly.  In other words, if the
user brings up the task information for more than one task, and they
change some information on some of the tasks, the software will keep
track of the correct changes for each task.

All of the routines in the GUI are independent of one another, so each
can be tested without the others being complete.  Since most of the
tests of the GUI involve integration testing rather than unit testing,
the modules from the various subsystems that are being attached should
have been coded and fully tested before the integration testing with
the GUI begins.  If the specific modules being integrated with the GUI
have been tested, then there will be a very good chance that if a
problem pops up during integration, it is almost certainly a problem
with integration, and not a problem with the module that the GUI is
being hooked too.  This type of software testing (modules first, and
then integration) often cuts down on the amount of time it takes to
debug a program, since it is either known or at least fairly certain
that the ``lower level'' routines are not at fault.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% For each top level module:
%
%	0. Describe the top level module
%
%	1. List the low-level modules that are invoked by the
% 	top level module
%
%	2. Discuss integration provisions and outline integration tests
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Order of integration}

The integration tests for the graphical user interface follow.  Since
a large portion of the graphical user interface is just integration of
other modules, most of the description for the testing of this code is
given here.  The modules will be integrated in the order that they are
completed in the test phase.  In other words the database functions
will be integrated with the GUI before any other functions, with the
file read and write following that, and then the calculations and
\LaTeX\ output functions.

Each button and menu item in the user interface will be tested to make
sure that the action associated with the button or menu item does what
it is supposed to.  Also, some actions like double-clicking on lists
have certain actions associated with them, and these actions will be
tested.

All of the menus in the system are on the project window, which is
illustrated in Figure~\ref{window:project}.  These menus, their
associated items, and the expected result from choosing an
item include:

\begin{figure}
\centering
\centerline{\psfig{figure=window-project.ps,height=4in}}
\caption[Project Window]{The project window and its menus.}
\label{window:project}
\end{figure}

\begin{description}

\begin{figure}
\centering
\centerline{\psfig{figure=menu-file.ps,height=1in}}
\caption[File Menu]{The file menu of the project window.}
\label{menu:file}
\end{figure}

\item[File Menu] Refer to Figure~\ref{menu:file} on
page~\pageref{menu:file}.
\begin{enumerate}
\item {\bf Load...}\\
Loads a project file into the interface.  If a project file has been
loaded previously, the information for that file is deleted and the
information for the new file replaces it.  If in fact a project file
was previously loaded, and a change has been made to it, the user will
be prompted on whether they would like to save the changes made to it
before loading the new file.
\item {\bf New Project}\\
Sets the database up to begin working on a new project.  If a project
is currently loaded and has been changed, the user is prompted on
whether they would like to save the changes made to it.
\item {\bf Save}\\
Saves the current project to a file with the same  name as that from
which it was loaded.  If it is a new project, the user is prompted for
a filename to save it to. 
\item {\bf Save as...}\\
Saves the current project to a file that is named by the user.
\end{enumerate}

\begin{figure}
\centering
\centerline{\psfig{figure=menu-chart.ps,height=1in}}
\caption[Chart Menu]{The chart menu of the project window.}
\label{menu:chart}
\end{figure}

\item[Chart Menu] Refer to Figure~\ref{menu:chart} on
page~\pageref{menu:chart}.
\begin{enumerate}
\item {\bf PERT}\\
Pops up the PERT chart for the currently loaded project.
\item {\bf Gantt}\\
Pops up the Gantt chart for the currently loaded project.
\end{enumerate}

\begin{figure}
\centering
\centerline{\psfig{figure=menu-analyze.ps,height=1in}}
\caption[Analyze Menu]{The analyze menu of the project window.}
\label{menu:analyze}
\end{figure}

\item[Analyze Menu] Refer to Figure~\ref{menu:analyze} on
page~\pageref{menu:analyze}.
\begin{enumerate}
\item {\bf Find Critical Path}\\
Finds the critical path in the task network.  This critical path will
be displayed in the PERT and Gantt charts once it has been calculated.
\item {\bf Check Dependencies}\\
Checks the dependencies of the tasks to make sure there are no
dependency loops.
\item {\bf Calculate Dates}\\
Calculates the earliest and latest start and end dates for the tasks
in the task network, along with the float for each task.  The duration
of each task, along with the start date of the first task, must have
been previously specified.
\end{enumerate}

\begin{figure}
\centering
\centerline{\psfig{figure=menu-export.ps,height=1in}}
\caption[Export Menu]{The export menu of the project window.}
\label{menu:export}
\end{figure}

\item[Export Menu] Refer to Figure~\ref{menu:export} on
page~\pageref{menu:export}.
\begin{enumerate}
\item {\bf Generate Task Sheet}\\
Generates the \LaTeX\ representation of a task sheet for the current
task network, in tabular form.
\item {\bf Generate PERT Chart}\\
Generates the \LaTeX\ representation of a PERT chart for the current
network.
\item {\bf Generate Gantt Chart}\\
Generates the \LaTeX\ representation of a Gantt chart for the current
network.
\end{enumerate}

In addition to these menu items, and their associated actions, there
are portions of the GUI in which the user can interact by
double-clicking.  When a user double-clicks on a list item, the
associated information for that item will be displayed.  Similarly, if
the user double-clicks on a PERT chart box or a Gantt chart bar, the
information for the item clicked on will be displayed.

\end{description}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Describe (briefly) the modules that are to be tested.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\paragraph{Modules to be tested}

For modules that have significant processing (rather than just being a
callback that calls a module in another subsystem), unit-tests are
described below.

\begin{description}

\item[store-data] Stores the data from the task information window
into the database.  Each item of the task information window will have
to be extracted and placed into a temporary variable, and then the
variables will be passed to the routine to create a new task
information node.  The task information node created will then be used
to add the task to the list.

\item[initialize-task-window] The task window will be filled with the
information for a single task.  This is essentially the opposite of
the store-data routine, which gets the information that has been
entered.

\item[popup-file-window] This routine will pop up the file window,
which gives a listing of the files in the current directory.  The
routine will have to read in the directory entries, store them into
the list used in the file window, and set up a string with the current
directory that the user is in.

\item[pert-popup] Gets the PERT formatting information from the
calculation subsystem, pops up a PERT window, and then calls the
display-pert-chart routine to do the actual drawing of the PERT chart.

\item[gantt-popup] Gets the Gantt formatting information from the
calculation subsystem, pops up a Gantt window, and then calls the
display-gantt-chart routine to actually draw the Gantt chart.

\end{description}

A description of these tests follows.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% The following subsubsection should be repeated for each module that
% is invoked by the top-level module.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Unit tests for store-data} 

\begin{description}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Describe the test for the module.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item[Description of tests:]\hfill\\
 For this module the testing centers
around making sure that the information extracted from the task window
is the same as the information that was actually entered into the
window.  The procedure will be to print out (to the screen) the
information received, and try several test cases, each time making
sure that what gets printed out is the same as what was entered.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Use of stubs or other software to facilitate the test
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item[Overhead software description:]\hfill\\ The database routines, or stubs
that match the database routine calling parameters will have to be
complete before this module is tested.  Also, for this routine and all
others that follow, the GUI code to set up the callbacks will have to
have been generated by {\tt gxv}.  Our current plan is to have
database routines completed and tested before the integration with the
GUI occurs.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% What data did you use to conduct the tests?
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item[Test case data:]\hfill\\ As with most of the graphical user interface,
no specific single test elements can be given (i.e., it is impossible
to enumerate all test cases).  Some things that will be tested (and
this is true for all part of the GUI that involve keyboard input)
include:
\begin{enumerate}
\item Verifying that the user can not enter too many characters and
overflow the buffer.
\item Verifying that if the user enters nothing at all for a field,
the user is either flagged for some input, or if empty input is
acceptable, the data gets stored in a fashion that indicates that it
was not entered by the user (for instance some special value for
integers, or empty strings for character data).
\item Verifying that only specified ranges of values can be entered
(e.g., a date of 14/75/92 would be flagged as incorrect).
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Briefly, what type of results do you expect?
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item[Expected results:]\hfill\\
It is expected that the data entered into the task information screen
is the same as the data that is extracted from that same screen for storage.

\end{description}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% DO NOT FILL OUT THE FOLLOWING SECTION FOR THE TESTING SPEC DELIVERABLE!!
% The testing results will be turned when the practice demo is given.
%
% For each top level module, describe the testing results.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%\subsubsection{Actual Test Results}

%----------------------------------------

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% The following subsubsection should be repeated for each module that
% is invoked by the top-level module.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Unit tests for initialize-task-window} 

\begin{description}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Describe the test for the module.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item[Description of tests:]\hfill\\ This routine takes a task as a parameter,
and fills the elements of the task information window with the
information from the task.  The test for this routine will involve
taking a task structure and filling it with data, and then calling the
routine to make sure it fills the task information window correctly.
The actual database routines will then be used to search for tasks and
display them in the task window.  Such tasks were previously stored
with store-data.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Use of stubs or other software to facilitate the test
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item[Overhead software description:]\hfill\\ The actual database routines
will be used in testing this routine, but prior to using those at
least a couple of tests will be done where the task structure is
filled ``by hand'' in a short routine that is hard-coded, and temporary.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% What data did you use to conduct the tests?
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item[Test case data:]\hfill\\ As with other modules of the GUI, several test
cases based on perceived problem areas (empty lists, etc.) along with
areas that we don't see there being a problem with.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Briefly, what type of results do you expect?
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item[Expected results:]\hfill\\ The data previously stored into the
task structure should be displayed in the task window correctly.

\end{description}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% DO NOT FILL OUT THE FOLLOWING SECTION FOR THE TESTING SPEC DELIVERABLE!!
% The testing results will be turned when the practice demo is given.
%
% For each top level module, describe the testing results.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%\subsubsection{Actual Test Results}

%----------------------------------------

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% The following subsubsection should be repeated for each module that
% is invoked by the top-level module.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Unit tests for popup-file-window}

\begin{description}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Describe the test for the module.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item[Description of tests:]\hfill\\ This routine will be tested to make sure
it lists all available files and directories in the file list.  It
will also be tested to make sure the filename that was selected from
the file list is actually the filename that gets returned to the
caller.  Finally tests will be made to make sure that the routine
correctly handles double-clicking on a directory (which means that the
directory should be entered).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Use of stubs or other software to facilitate the test
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item[Overhead software description:]\hfill\\ A routine that calls this
routine will have to be provided.  Since this routine will be a
callback it is most likely the case that it will be tested after the
files are generated by Guide.  In that case, the routine that calls
this routine will print out the filename returned.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% What data did you use to conduct the tests?
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item[Test case data:]\hfill\\ Various directories will be entered while using
the routine.  Some of them will be set up to contain no files, and
others will have several dozen files in them.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Briefly, what type of results do you expect?
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item[Expected results:]\hfill\\ It is expected that the file chosen from the
list is the one that is passed back to the calling routine.  In the
case of selecting a directory the correct response would be to enter
the directory selected.

\end{description}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% DO NOT FILL OUT THE FOLLOWING SECTION FOR THE TESTING SPEC DELIVERABLE!!
% The testing results will be turned when the practice demo is given.
%
% For each top level module, describe the testing results.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%\subsubsection{Actual Test Results}

%----------------------------------------

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% The following subsubsection should be repeated for each module that
% is invoked by the top-level module.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Unit tests for pert-popup} 

\begin{description}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Describe the test for the module.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item[Description of tests:]\hfill\\ This routine will be tested to make sure
it is correctly retrieving the formatting information from the
calculation subsystem, and correctly sending the information to the
routines that do the actual display of the PERT chart to a canvas.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Use of stubs or other software to facilitate the test
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item[Overhead software description:]\hfill\\ The calculation module that
determines the positioning of items in the PERT chart will have to be
complete, along with the routines that draw single PERT boxes.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% What data did you use to conduct the tests?
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item[Test case data:]\hfill\\ The test case data for this routine will
include the entire task list which we used in MS-Project to generate
our PERT and Gantt charts for the project plan.  The output of
MS-Project will be compared to the output of our project.  In addition
several test cases will be generated by hand to test out areas that we
think my cause problems, such as dependency lines that cross several
pages.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Briefly, what type of results do you expect?
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item[Expected results:]\hfill\\ The results should be similar to that
generated by MS-Project, and for smaller tests should be similar to
those charts generated by hand.

\end{description}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% DO NOT FILL OUT THE FOLLOWING SECTION FOR THE TESTING SPEC DELIVERABLE!!
% The testing results will be turned when the practice demo is given.
%
% For each top level module, describe the testing results.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%\subsubsection{Actual Test Results}

%----------------------------------------

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% The following subsubsection should be repeated for each module that
% is invoked by the top-level module.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Unit tests for gantt-popup} 

\begin{description}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Describe the test for the module.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item[Description of tests:]\hfill\\ This routine will be tested to verify it
correctly retrieves the Gantt chart formatting information from the
calculation module, and that it passes this information on correctly
to the routines which actually draw the Gantt charts.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Use of stubs or other software to facilitate the test
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item[Overhead software description:]\hfill\\ The routines mentioned in the
description of tests will have to be complete before this can be tested.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% What data did you use to conduct the tests?
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item[Test case data:]\hfill\\ The data used for this test will be the same as
that used in testing the pert-popup routine.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Briefly, what type of results do you expect?
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item[Expected results:]\hfill\\ The results should be very similar to that
generated by MS-Project.

\end{description}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% DO NOT FILL OUT THE FOLLOWING SECTION FOR THE TESTING SPEC DELIVERABLE!!
% The testing results will be turned when the practice demo is given.
%
% For each top level module, describe the testing results.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%\subsubsection{Actual Test Results}
@


1.5
log
@*** empty log message ***
@
text
@d279 1
a279 1
\item Veryifying that if the user enters nothing at all for a field,
@


1.4
log
@*** empty log message ***
@
text
@a291 1

d345 2
a346 4
\item[Expected results:]\hfill\\

The data previously stored into the task structure should be displayed
in the task window correctly.
@


1.3
log
@*** empty log message ***
@
text
@d249 2
a250 1
\item[Description of tests:] For this module the testing centers
d260 1
a260 1
\item[Overhead software description:] The database routines, or stubs
d271 1
a271 1
\item[Test case data:] As with most of the graphical user interface,
d291 1
a291 1
\item[Expected results:]
d319 1
a319 1
\item[Description of tests:] This routine takes a task as a parameter,
d331 1
a331 1
\item[Overhead software description:] The actual database routines
d339 1
a339 1
\item[Test case data:] As with other modules of the GUI, several test
d346 1
a346 1
\item[Expected results:]
d374 1
a374 1
\item[Description of tests:] This routine will be tested to make sure
d385 1
a385 1
\item[Overhead software description:] A routine that calls this
d394 1
a394 1
\item[Test case data:] Various directories will be entered while using
d401 1
a401 1
\item[Expected results:] It is expected that the file chosen from the
d429 1
a429 1
\item[Description of tests:] This routine will be tested to make sure
d437 1
a437 1
\item[Overhead software description:] The calculation module that
d444 1
a444 1
\item[Test case data:] The test case data for this routine will
d455 1
a455 1
\item[Expected results:] The results should be similar to that
d482 1
a482 1
\item[Description of tests:] This routine will be tested to verify it
d490 1
a490 1
\item[Overhead software description:] The routines mentioned in the
d496 1
a496 1
\item[Test case data:] The data used for this test will be the same as
d502 1
a502 1
\item[Expected results:] The results should be very similar to that
a513 275

%----------------------------------------

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% The following subsubsection should be repeated for each module that
% is invoked by the top-level module.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Unit tests for } 

\begin{description}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Describe the test for the module.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item[Description of tests:] 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Use of stubs or other software to facilitate the test
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item[Overhead software description:]

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% What data did you use to conduct the tests?
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item[Test case data:] 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Briefly, what type of results do you expect?
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item[Expected results:]

\end{description}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% DO NOT FILL OUT THE FOLLOWING SECTION FOR THE TESTING SPEC DELIVERABLE!!
% The testing results will be turned when the practice demo is given.
%
% For each top level module, describe the testing results.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%\subsubsection{Actual Test Results}

%----------------------------------------

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% The following subsubsection should be repeated for each module that
% is invoked by the top-level module.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Unit tests for } 

\begin{description}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Describe the test for the module.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item[Description of tests:] 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Use of stubs or other software to facilitate the test
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item[Overhead software description:]

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% What data did you use to conduct the tests?
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item[Test case data:] 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Briefly, what type of results do you expect?
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item[Expected results:]

\end{description}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% DO NOT FILL OUT THE FOLLOWING SECTION FOR THE TESTING SPEC DELIVERABLE!!
% The testing results will be turned when the practice demo is given.
%
% For each top level module, describe the testing results.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%\subsubsection{Actual Test Results}

%----------------------------------------

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% The following subsubsection should be repeated for each module that
% is invoked by the top-level module.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Unit tests for } 

\begin{description}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Describe the test for the module.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item[Description of tests:] 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Use of stubs or other software to facilitate the test
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item[Overhead software description:]

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% What data did you use to conduct the tests?
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item[Test case data:] 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Briefly, what type of results do you expect?
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item[Expected results:]

\end{description}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% DO NOT FILL OUT THE FOLLOWING SECTION FOR THE TESTING SPEC DELIVERABLE!!
% The testing results will be turned when the practice demo is given.
%
% For each top level module, describe the testing results.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%\subsubsection{Actual Test Results}

%----------------------------------------

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% The following subsubsection should be repeated for each module that
% is invoked by the top-level module.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Unit tests for } 

\begin{description}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Describe the test for the module.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item[Description of tests:] 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Use of stubs or other software to facilitate the test
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item[Overhead software description:]

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% What data did you use to conduct the tests?
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item[Test case data:] 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Briefly, what type of results do you expect?
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item[Expected results:]

\end{description}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% DO NOT FILL OUT THE FOLLOWING SECTION FOR THE TESTING SPEC DELIVERABLE!!
% The testing results will be turned when the practice demo is given.
%
% For each top level module, describe the testing results.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%\subsubsection{Actual Test Results}

%----------------------------------------

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% The following subsubsection should be repeated for each module that
% is invoked by the top-level module.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Unit tests for } 

\begin{description}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Describe the test for the module.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item[Description of tests:] 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Use of stubs or other software to facilitate the test
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item[Overhead software description:]

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% What data did you use to conduct the tests?
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item[Test case data:] 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Briefly, what type of results do you expect?
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item[Expected results:]

\end{description}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% DO NOT FILL OUT THE FOLLOWING SECTION FOR THE TESTING SPEC DELIVERABLE!!
% The testing results will be turned when the practice demo is given.
%
% For each top level module, describe the testing results.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%\subsubsection{Actual Test Results}

%----------------------------------------

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% The following subsubsection should be repeated for each module that
% is invoked by the top-level module.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Unit tests for } 

\begin{description}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Describe the test for the module.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item[Description of tests:] 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Use of stubs or other software to facilitate the test
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item[Overhead software description:]

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% What data did you use to conduct the tests?
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item[Test case data:] 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Briefly, what type of results do you expect?
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item[Expected results:]

\end{description}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% DO NOT FILL OUT THE FOLLOWING SECTION FOR THE TESTING SPEC DELIVERABLE!!
% The testing results will be turned when the practice demo is given.
%
% For each top level module, describe the testing results.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%\subsubsection{Actual Test Results}

%----------------------------------------

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% The following subsubsection should be repeated for each module that
% is invoked by the top-level module.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Unit tests for } 

\begin{description}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Describe the test for the module.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item[Description of tests:] 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Use of stubs or other software to facilitate the test
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item[Overhead software description:]

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% What data did you use to conduct the tests?
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item[Test case data:] 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Briefly, what type of results do you expect?
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item[Expected results:]

\end{description}



@


1.2
log
@*** empty log message ***
@
text
@d786 2
@


1.1
log
@Initial revision
@
text
@a0 3
\documentstyle[fullpage,psfig]{article}
\begin{document}

a785 1
\end{document}
@
